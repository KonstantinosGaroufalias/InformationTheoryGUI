ΟΔΗΓΙΕΣ ΧΡΗΣΗΣ ΕΦΑΡΜΟΓΗΣ
===============================================

1)Tab "Εντροπία"

Σε αυτό το tab ο χρήστης μπορεί να υπολογίσει την
Εντροπία , την Πληροφορία , την Απόκλιση Kullback-Lieber ,
την Συνδετική Εντροπία και την Υπο συνθήκη Εντροπία δίνοντας
τις πιθανότητες Px ή Py  με κενό , δηλαδή οτιδήποτε
μπορεί να χρειαστεί ενισχύσει καλύτερα τις βασικές αρχές
της Θεωρίας Της Πληροφορίας λύνοντας διάφορα
παραδείγματα και ασκήσεις ,με πιό γρήγορο τρόπο
από ο,τι με το χέρι.

TIP: Όλες οι πιθανότητες στη εφαρμογή μπορούν να
εισαχθούν χωρίς το " 0 " στην αρχή, δηλαδή με τη
μορφή Px = .2 .3 .5

TIP: Για τον υπολογισμό εντροπίας από δίαυλο πληροφορίας
ο χρήστης θα πρέπει να θυμάται πως σε ένα πίνακα P(XY)
το άθροισμα κάθε γραμμής του πίνακα ισούται με τις
πιθανότητες της κατανομής Px, και αναλόγως οι στήλες
για την κατανομή Py.

TIP: Για να είναι σωστή η ανάλυση, το άθροισμα των πιθανοτήτων
πρέπει να είναι 1.0 (εμφανίζεται σχετικό μήνυμα αν όχι).

ΘΕΩΡΙΑ: Η εντροπία H(X) μετρά την αβεβαιότητα μιας
πηγής. Όσο πιο "ομοιόμορφη" είναι η κατανομή, τόσο
μεγαλύτερη είναι η εντροπία. Για παράδειγμα:
Px = [0.5, 0.5] , H(X) = 1.0 bit (μέγιστη αβεβαιότητα)
Px = [0.99, 0.01] , H(X) = 0.08 bits (χαμηλή αβεβαιότητα)
Αντίθετα η απόκλιση KL (Kullback-Leibler) μετρά πόσο
"διαφορετική" είναι η κατανομή P από την Q.

===============================================


2)Tab "Κανάλι"

Σε αυτό το tab ο χρήστης μπορεί να δεί και να
αναλύσει την γραφική παράσταση Χωρητικότητας με
σφάλμα e του δυαδικού συμμετρικού καναλιού BSC ,
να υπολογίσει χωρητικότητα διαύλου (αφού πρώτα
γίνει η σωστή επιλογή του Μ ,αν όχι υπάρχει
ανάλογο μύνημα που εξηγεί το λάθος).

TIP: Η εισαγωγή δεδομένων μπορεί να γίνει
πιο γρήγορα με το πάτημα του πλήκτρου TAB
για να εισάξει δεδομένα στο επόμενο κελί

TIP: Ο χρήστης μπορεί και να επαληθεύσει την
χωρητικότητα του BSC καναλιού στο 2ο subtab ,καθώς

P(Y|X) = [(e,1-e)
         (1-e,e)]

Τέλος ο χρήστης μπορεί να δημιουργήσει τον
τελικό πίνακα απο μια αλυσίδα διαύλων και
να βρει την χωρητικότητα.


ΘΕΩΡΙΑ: Η χωρητικότητα C ενός καναλιού είναι ο
μέγιστο ρυθμός (bits/symbol) με τον οποίο μπορούμε να
μεταδώσουμε πληροφορία με χωρίς κάποιο σφάλμα. Για το BSC:

C = 0 όταν e = 0.5 (πλήρης θόρυβος, άχρηστο κανάλι)
C = 1 όταν e = 0 (τέλειο κανάλι, χωρίς σφάλματα)
Παρατηρήστε τη γραφική παράσταση , είναι συμμετρική γύρω
από το e = 0.5!

ΘΕΩΡΙΑ: Σε αλυσίδα καναλιών P₁ × P₂ × ... × Pₙ,
η συνολική χωρητικότητα είναι πάντα μικρότερη απο
την ελάχιστη χωρητικότητα του πλήθους (C₁, C₂, ..., Cₙ).
Δηλαδή το "αδύναμο" κανάλι καθορίζει το όριο! Δοκιμάστε
να συνδυάσετε ένα καλό κανάλι (e=0.1) με ένα κακό
(e=0.4) και δείτε τι θα συμβαίνει και συγκρίνετα τις
διαφορές.

===============================================

3)Tab "Ανάλυση Κωδίκων & Huffman"

Σε αυτό το tab, ο χρήστης μπορεί να αναλύσει ή να
δημιουργήσει κώδικες Huffman. Στο πρώτο subtab
εισάγετε ένα λεξικό κωδίκων και τις αντίστοιχες πιθανότητες.
Η εφαρμογή σας ενημερώνει αυτόματα για ιδιότητες του κώδικα
και Πατώντας "Προβολή Δένδρου Huffman" ο κώδικας οπτικοποιείται
ως δέντρο, το οποίο βοηθάει τον χρήστη να δεί γραφικά τη δομή
κάθε κωδικού (με χρήση NetworkX/Matplotlib).
Στο δεύτερο subtab , μπορείτε να εισάγετε οποιοδήποτε κείμενο
και να δημιουργηθεί αυτόματα το Huffman λεξικό και το αντίστοιχο
δέντρο, με απεικόνιση συχνότητας συμβόλων.

TIP: Στην ανάλυση κειμένου, σύμβολα με μεγαλύτερη συχνότητα
έχουν μικρότερου μήκους κωδικές λέξεις όπως προβλέπει
ο αλγόριθμος Huffman.

===============================================
